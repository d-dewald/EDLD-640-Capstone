install.packages("reticulate", dependencies = TRUE)
install.packages("reticulate", dependencies = TRUE)
reticulate::conda_config(append = TRUE, channels = "conda-forge")
require(reticulate)
reticulate::py_install("tensorflow==2.0", pip = TRUE)
use_condaenv("myenv")
conda_create("myenv")
use_condaenv("myenv")
Sys.setenv(RETICULATE_PYTHON = "C:/Users/ddewa/AppData/Local/r-miniconda/envs/myenv/python.exe")
use_condaenv("myenv")
conda_create("myenv", packages = c("python=3.11.2", "pip"))
reticulate::py_install("tensorflow==2.0", pip = TRUE)
reticulate::py_install("tensorflow", pip = TRUE)
Sys.setenv(RETICULATE_PYTHON = "C:/Users/ddewa/AppData/Local/r-miniconda/envs/capstone/python.exe")
conda_install(envname = 'capstone',
packages = 'torch',
pip = TRUE,
force = TRUE)
conda_install(envname = 'capstone',
packages = 'torch',
pip = TRUE,
force = TRUE)
library(papaja)
r_refs("r-references.bib")
library(tidyverse)
library(here)
library(rio)
library(tidytext)
library(dplyr)
library(tidyr)
library(devtools)
library(tinytex)
library(readr)
library(magrittr)
library(recipes)
library(psych)
library(finalfit)
library(caret)
library(glmnet)
library(recipes)
library(cutpointr)
library(kableExtra)
library(pastecs)
# loading datasets
mydata <- import(here("data", "pedagogy_data.xlsx"))
textdata <- import(here("data", "text_data.xlsx"))
# fixing demographic variables
# pivoting longer
mydata <- mydata %>%
pivot_longer(cols = starts_with("f"),
names_to = "func",
values_to = "pedagogy")
# renaming two variables in funct column and getting rid of old func column
fun <- c(fsqueak = "squeak", flight = "light")
mydata$funct <-
as.character(fun[mydata$func])
mydata$func <- NULL
rm(fun)
# parsing words from the 'pedagogy' (text) column
tidy_words <- mydata %>%
unnest_tokens(word, pedagogy)
# removing numbers
tidy_words <- tidy_words[-grep("\\b\\d+\\b", tidy_words$word),]
# removing common/under-informative words
exclu <- tibble(word = c("the", "this", "I"))
tidy_words <- tidy_words %>%
anti_join(exclu, by = "word")
#plot
tidy_words %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>% # make y-axis ordered by n
slice(1:15) %>% # select only the first 15 rows
ggplot(aes(n, word)) +
geom_col(fill = "royalblue", alpha = .7) +
scale_x_continuous(expand = c(0,0)) +
theme_minimal() +
theme(
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_line(color = "gray80")
) +
labs(
x = "Word Frequency",
y = "Word",
title = "Top 15 most frequently occurring words across all pedagogy types",
)
# visualing: word cloud
library(wordcloud)
tokens = textdata %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
# top words
word_count = tokens%>%
group_by(word)%>%
summarise(count = n())%>%
arrange(desc(count))%>%
slice(1:10)
# word cloud--zoom in
cloud <- tokens %>%
group_by(source, word) %>%
summarise(count = n())%>%
arrange(desc(count))%>%
slice(1:10)
wordcloud(tokens$word, max.words = 75, colors=brewer.pal(6, "Dark2"))
tidy_words %>%
group_by(condition) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>% # make y-axis ordered by n
slice(1:15) %>% # select only the first 15 rows
ggplot(aes(n, word, fill = condition)) +
geom_col(alpha = .7) +
facet_wrap(~condition) +
scale_x_continuous(expand = c(0,0)) +
theme_minimal() +
theme(
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_line(color = "gray80")
) +
labs(
x = "Word Frequency",
y = "Word",
title = "Top 15 most frequently occurring words by condition",
)
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
# sentiment analysis
library(RColorBrewer)
# sentiment1 = textdata %>% #this allows us to retain the row number/the tweet
#  unnest_tokens(word, text)%>% # this unnests the tweets into words
#  anti_join(stop_words)%>% #removes common words (stop words)
#  left_join(get_sentiments("bing"))
#sentiment2 = textdata %>% #this allows us to retain the row number/the tweet
#  unnest_tokens(word, text)%>% # this unnests the tweets into words
#  anti_join(stop_words)%>% #removes common words (stop words)
#  left_join(get_sentiments("nrc"))
#sentiment3 = textdata %>% #this allows us to retain the row number/the tweet
#  unnest_tokens(word, text)%>% # this unnests the tweets into words
#  anti_join(stop_words)%>% #removes common words (stop words)
#  left_join(get_sentiments("loughran"))
#sentiment4 = textdata %>% #this allows us to retain the row number/the tweet
#  unnest_tokens(word, text)%>% # this unnests the tweets into words
#  anti_join(stop_words)%>% #removes common words (stop words)
#  left_join(get_sentiments("afinn"))
sentimentdata <- import(here("data", "sentiment_an.xlsx"))
sentiment_by_condition <- sentimentdata %>%
group_by(condition, analysis) %>%
count(sentiment)
# table of sentiment for four groups ("bing", "nrc", "afinn", "loughran")
sentimenttable <- import(here("data", "sentiment_table.xlsx"))
table <- sentimenttable[1:2, 2:11]
options(kableExtra.auto_format = FALSE)
library(kableExtra)
table %>%
kbl(caption = "Sentiment by analysis tool") %>%
kable_classic(html_font = "Cambria") %>%
column_spec(column = 1:10, width = "0.57in") %>%
footnote(general_title = "Note.", footnote_as_chunk=TRUE, threeparttable=TRUE, general = "Positive (Pos) and Negative (Neg) sentiment analysis by individual words using 4 analysis tools: bing, nrc, loughran, and afinn. Results demonstrate that Total Positive & Negative sentiment was roughly equal by condition (enhance or constrain). However, positive sentiment was slightly higher for the enhance condition and negative sentiment was slight higher for the constrain condition, which is the expected result.")
outcome <- c('sentiment')
ID <- c('id')
categorical <- c('condition', 'source', 'function', 'count')
blueprint <- recipe(x  = sentimentdata,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',4), 'outcome', 'ID')) %>%
step_zv(all_of(categorical))
blueprint <- recipe(x  = sentimentdata,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',4), 'outcome', 'ID')) %>%
step_zv(all_of(categorical))
View(sentimentdata)
sentiment <- import(here("data", "sentiment.xlsx"))
blueprint <- recipe(x  = sentiment,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',4), 'outcome', 'ID')) %>%
step_zv(all_of(categorical))
View(sentiment)
sentiment <- sentiment %>%
group_by(condition) %>%
count(sentiment)
View(sentiment)
sentiment <- import(here("data", "sentiment.xlsx"))
categorical <- c('condition', 'source', 'function', 'sentiment_numeric')
blueprint <- recipe(x  = sentiment,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',4), 'outcome', 'ID')) %>%
step_zv(all_of(categorical))
set.seed(11102021)  # for reproducibility
sen      <- sample(1:nrow(sentiment), round(nrow(sentiment) * 0.8))
sen_train  <- sentiment[sen, ]
sen_test  <- sentiment[-sen, ]
set.seed(11152021) # for reproducibility
sen_tr = sen_train[sample(nrow(sen_train)),]
folds = cut(seq(1,nrow(sen_tr)),breaks=10,labels=FALSE)
for(i in 1:10){
sen.indices[[i]] <- which(folds!=i)
}
sen.indices <- vector('list',10)
for(i in 1:10){
sen.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method    = "cv",
index           = sen.indices,
classProbs      = TRUE,
summaryFunction = mnLogLoss)
# Train the model
caret_mod <- caret::train(blueprint,
data      = sen_tr,
method    = "glm",
family    = 'binomial',
metric    = 'logLoss',
trControl = cv)
caret_mod
predicted_test <- predict(caret_mod, sen_test, type='prob')
head(predicted_test)
# Evaluate the model on the test dataset
predicted_te <- predict(caret_mod, sen_test)
predicted_te <- as.numeric(predicted_te)
# Evaluate the model on the test dataset
predicted_te <- predict(caret_mod, sen_test)
predicted_eval <- data.frame(predicted_te, sen_test_numeric)
sen_test_numeric <- sen_test$sentiment_numeric
predicted_eval <- data.frame(predicted_te, sen_test_numeric)
predicted_eval <- predicted_eval[complete.cases(predicted_eval), ]
rsq_te <- cor(predicted_eval$predicted_te,predicted_eval$sen_test_numeric)^2
rsq_te
View(predicted_eval)
mae_te <- mean(abs(predicted)eval$sen_test_numeric - predicted_te))
mae_te <- mean(abs(predicted_eval$sen_test_numeric - predicted_te))
library(writeexl)
library(writexl)
write_xlsx(predicted_eval, "predicted_eval.xlsx")
predicted_eval <- import(here("data", "predicted_eval.xlsx"))
rsq_te <- cor(predicted_eval$predicted_te,predicted_eval$sen_test_numeric)^2
rsq_te
mae_te <- mean(abs(predicted_eval$sen_test_numeric - predicted_te))
mae_te <- mean(abs(predicted_eval$sen_test_numeric - predicted_eval$predicted_te))
mae_te
rmse_te <- sqrt(mean((predicted_eval$sen_test_numeric - predicted_eval$predicted_te)^2))
rmse_te
categorical <- c('condition', 'source', 'function')
blueprint <- recipe(x  = sentiment,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',3), 'outcome', 'ID')) %>%
step_zv(all_of(categorical))
set.seed(11102021)  # for reproducibility
sen      <- sample(1:nrow(sentiment), round(nrow(sentiment) * 0.8))
sen_train  <- sentiment[sen, ]
sen_test  <- sentiment[-sen, ]
set.seed(11152021) # for reproducibility
sen_tr = sen_train[sample(nrow(sen_train)),]
folds = cut(seq(1,nrow(sen_tr)),breaks=10,labels=FALSE)
sen.indices <- vector('list',10)
for(i in 1:10){
sen.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method    = "cv",
index           = sen.indices,
classProbs      = TRUE,
summaryFunction = mnLogLoss)
# Train the model
caret_mod <- caret::train(blueprint,
data      = sen_tr,
method    = "glm",
family    = 'binomial',
metric    = 'logLoss',
trControl = cv)
caret_mod
# Evaluate the model on the test dataset
predicted_te <- predict(caret_mod, sen_test)
predicted_te <- as.numeric(predicted_te)
sen_test_numeric <- sen_test$sentiment_numeric
predicted_eval <- data.frame(predicted_te, sen_test_numeric)
predicted_eval <- predicted_eval[complete.cases(predicted_eval), ]
predicted_eval <- import(here("data", "predicted_eval.xlsx"))
rsq_te <- cor(predicted_eval$predicted_te,predicted_eval$sen_test_numeric)^2
rsq_te
mae_te <- mean(abs(predicted_eval$sen_test_numeric - predicted_eval$predicted_te))
mae_te
predicted_eval <- data.frame(predicted_te, sen_test_numeric)
predicted_eval <- predicted_eval[complete.cases(predicted_eval), ]
rsq_te <- cor(predicted_eval$predicted_te,predicted_eval$sen_test_numeric)^2
rsq_te
mae_te <- mean(abs(predicted_eval$sen_test_numeric - predicted_eval$predicted_te))
mae_te
rmse_te <- sqrt(mean((predicted_eval$sen_test_numeric - predicted_eval$predicted_te)^2))
rmse_te
