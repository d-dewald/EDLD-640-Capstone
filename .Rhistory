folds = cut(seq(1,nrow(rank_tr)),breaks=10,labels=FALSE)
# Create the list for each fold
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
# Cross-validation settings
cv <- trainControl(method = "cv",
index  = my.indices)
require(caret)
require(kknn)
getModelInfo()$kknn$parameters
# Hyperparameter Tuning Grid
grid <- expand.grid(kmax    = 3:25,
distance = c(1,2,3),
kernel   = c('epanechnikov','rectangular'))
# grid
require(doParallel)
ncores <- 8
cl <- makePSOCKcluster(ncores)
registerDoParallel(cl)
textdummy$source <- as.vector(textdummy$source)
textdummy$rank <- as.vector(textdummy$rank)
textdummy$condition <- as.vector(textdummy$condition)
textdummy$funct <- as.vector(textdummy$funct)
textdummy$id <- as.vector(textdummy$id)
outcome <- c('rank')
ID <- c('id')
categorical <- c('condition', 'source', 'function')
blueprint_textdummy <- recipe(x  = textdummy,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',3), 'outcome', 'ID'),
step_dummy(all_of(categorical),one_hot=TRUE),
step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0,
skip = FALSE, one_hot = TRUE),
step_normalize(all_numeric_predictors()),
na.pass = TRUE)
textdummy <-import(here("data", "text_dummy.xlsx"))
set.seed(10152022) # for reproducibility
loc <- sample(1:nrow(textdummy), round(nrow(textdummy) * 0.9))
rank_tr <- textdummy[loc, ]
rank_te <- textdummy[-loc, ]
# create row indices for 10-folds
#randomly shuffle training data
rank_tr = rank_tr[sample(nrow(rank_tr)),]
# Create 10 folds with equal size
folds = cut(seq(1,nrow(rank_tr)),breaks=10,labels=FALSE)
# Create the list for each fold
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
# Cross-validation settings
cv <- trainControl(method = "cv",
index  = my.indices)
require(caret)
require(kknn)
getModelInfo()$kknn$parameters
# Hyperparameter Tuning Grid
grid <- expand.grid(kmax    = 3:25,
distance = c(1,2,3),
kernel   = c('epanechnikov','rectangular'))
# grid
require(doParallel)
ncores <- 8
cl <- makePSOCKcluster(ncores)
registerDoParallel(cl)
# Train the model
textdummy$source <- as.vector(textdummy$source)
textdummy$rank <- as.vector(textdummy$rank)
textdummy$condition <- as.vector(textdummy$condition)
textdummy$funct <- as.vector(textdummy$funct)
textdummy$id <- as.vector(textdummy$id)
outcome <- c('rank')
ID <- c('id')
categorical <- c('condition', 'source', 'function')
blueprint_textdummy <- recipe(x  = textdummy,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',3), 'outcome', 'ID'))
blueprint_textdummy <- recipe(x  = textdummy,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',3), 'outcome', 'ID'))
View(textdummy)
categorical <- c('condition', 'source', 'funct')
blueprint_textdummy <- recipe(x  = textdummy,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',3), 'outcome', 'ID'))
caret_knn <- caret::train(blueprint_textdummy,
data      = rank_tr,
method    = "kknn",
trControl = cv,
tuneGrid  = grid)
View(caret_knn)
plot(caret_knn)
caret_knn$bestTune
# checking performance of knn algorithm on test dataset
predicted_te <- predict(caret_knn, rank_te)
# checking performance of knn algorithm on test dataset
predicted_te <- predict(caret_knn,rank_te)
View(rank_te)
# checking performance of knn algorithm on test dataset
predicted_te <- predict(caret_knn,rank_te, type = 'prob')
# checking performance of knn algorithm on test dataset
predicted_te <- kknn::predict(caret_knn,rank_te)
require(knn)
require(kknn)
# checking performance of knn algorithm on test dataset
predicted_te <- predict(caret_knn$finalModel, newdata = rank_te)
cor(rank_te$rank, predicted_te)^2
# rmse
sqrt(mean(rank_te$rank - predicted_te)*2))
# rmse
sqrt(mean((rank_te$rank - predicted_te)*2))
mean(abs(rank_te$rank -predicted_te))
library(papaja)
r_refs("r-references.bib")
library(tidyverse)
library(here)
library(rio)
library(tidytext)
library(dplyr)
library(tidyr)
library(devtools)
library(tinytex)
library(readr)
library(magrittr)
library(recipes)
library(psych)
library(finalfit)
library(caret)
library(glmnet)
library(recipes)
library(cutpointr)
library(kableExtra)
library(pastecs)
# loading data + data cleaning
mydata <- import(here("data", "pedagogy_data.xlsx"))
textdata <- import(here("data", "text_data.xlsx"))
# fixing demographic variables
# pivoting longer
mydata <- mydata %>%
pivot_longer(cols = starts_with("f"),
names_to = "func",
values_to = "pedagogy")
# renaming two variables in funct column and getting rid of old func column
fun <- c(fsqueak = "squeak", flight = "light")
mydata$funct <-
as.character(fun[mydata$func])
mydata$func <- NULL
rm(fun)
# parsing words from the 'pedagogy' (text) column
tidy_words <- mydata %>%
unnest_tokens(word, pedagogy)
# removing numbers
tidy_words <- tidy_words[-grep("\\b\\d+\\b", tidy_words$word),]
# removing common/under-informative words
exclu <- tibble(word = c("the", "this", "I"))
tidy_words <- tidy_words %>%
anti_join(exclu, by = "word")
#plot
tidy_words %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>% # make y-axis ordered by n
slice(1:15) %>% # select only the first 15 rows
ggplot(aes(n, word)) +
geom_col(fill = "royalblue", alpha = .7) +
scale_x_continuous(expand = c(0,0)) +
theme_minimal() +
theme(
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_line(color = "gray80")
) +
labs(
x = "Word Frequency",
y = "Word",
title = "Figure 1: Top 15 most frequently occurring words across all pedagogy types",
)
# visualing: word cloud
library(wordcloud)
tokens = textdata %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
# top words
word_count = tokens%>%
group_by(word)%>%
summarise(count = n())%>%
arrange(desc(count))%>%
slice(1:10)
# word cloud--zoom in
cloud <- tokens %>%
group_by(source, word) %>%
summarise(count = n())%>%
arrange(desc(count))%>%
slice(1:10)
wordcloud(tokens$word, max.words = 75, colors=brewer.pal(6, "Dark2"))
tidy_words %>%
group_by(condition) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>% # make y-axis ordered by n
slice(1:15) %>% # select only the first 15 rows
ggplot(aes(n, word, fill = condition)) +
geom_col(alpha = .7) +
facet_wrap(~condition) +
scale_x_continuous(expand = c(0,0)) +
theme_minimal() +
theme(
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_line(color = "gray80")
) +
labs(
x = "Word Frequency",
y = "Word",
title = "Figure 3: Top 15 most frequently occurring words by condition",
)
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
sentimentdata <- import(here("data", "sentiment_an.xlsx"))
sentiment <- import(here("data", "sentiment.xlsx"))
sentiment_by_condition <- sentimentdata %>%
group_by(condition, analysis) %>%
count(sentiment)
# table of sentiment for four groups ("bing", "nrc", "afinn", "loughran")
sentimenttable <- import(here("data", "sentiment_table.xlsx"))
table <- sentimenttable[1:2, 2:11]
options(kableExtra.auto_format = FALSE)
library(kableExtra)
table %>%
kbl(caption = "Sentiment by analysis tool") %>%
kable_classic(html_font = "Cambria") %>%
column_spec(column = 1:10, width = "0.57in") %>%
footnote(general_title = "Note.", footnote_as_chunk=TRUE, threeparttable=TRUE, general = "Positive (Pos) and Negative (Neg) sentiment analysis by individual words using 4 analysis tools: bing, nrc, loughran, and afinn. Results demonstrate that Total Positive & Negative sentiment was roughly equal by condition (enhance or constrain). However, positive sentiment was slightly higher for the enhance condition and negative sentiment was slight higher for the constrain condition, which is the expected result.")
# Recipe for the sentiment dataset
outcome <- c('sentiment')
ID <- c('id')
categorical <- c('condition', 'source', 'function')
blueprint <- recipe(x  = sentiment,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',3), 'outcome', 'ID')) %>%
step_zv(all_of(categorical))
# splitting data into training and testing
# Let the training data have the 80% of cases and the test data have the 20% of the cases.
set.seed(11102021)  # for reproducibility
sen      <- sample(1:nrow(sentiment), round(nrow(sentiment) * 0.8))
sen_train  <- sentiment[sen, ]
sen_test  <- sentiment[-sen, ]
# 10-fold cross-validation without regularization
set.seed(11152021) # for reproducibility
sen_tr = sen_train[sample(nrow(sen_train)),]
# Creating 10 folds with equal size
folds = cut(seq(1,nrow(sen_tr)),breaks=10,labels=FALSE)
# Creating the list for each fold
sen.indices <- vector('list',10)
for(i in 1:10){
sen.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method    = "cv",
index           = sen.indices,
classProbs      = TRUE,
summaryFunction = mnLogLoss)
# Train the model
caret_mod <- caret::train(blueprint,
data      = sen_tr,
method    = "glm",
family    = 'binomial',
metric    = 'logLoss',
trControl = cv)
# caret_mod
# Evaluate the model on the test data
# Predict the probabilities for the observations in the test dataset
predicted_test <- predict(caret_mod, sen_test, type='prob')
# head(predicted_test)
# Evaluate the model on the test dataset
predicted_te <- predict(caret_mod, sen_test)
predicted_te <- as.numeric(predicted_te)
sen_test_numeric <- sen_test$sentiment_numeric
predicted_eval <- data.frame(predicted_te, sen_test_numeric)
predicted_eval <- predicted_eval[complete.cases(predicted_eval), ]
rsq_te <- cor(predicted_eval$predicted_te,predicted_eval$sen_test_numeric)^2
# rsq_te
mae_te <- mean(abs(predicted_eval$sen_test_numeric - predicted_eval$predicted_te))
# mae_te
rmse_te <- sqrt(mean((predicted_eval$sen_test_numeric - predicted_eval$predicted_te)^2))
# rmse_te
# import data
# textdummy <- import(here("data", "text_data_dummy.xlsx"))
textdummy <-import(here("data", "text_dummy.xlsx"))
# train and test split
set.seed(10152022) # for reproducibility
loc <- sample(1:nrow(textdummy), round(nrow(textdummy) * 0.9))
rank_tr <- textdummy[loc, ]
rank_te <- textdummy[-loc, ]
# create row indices for 10-folds
#randomly shuffle training data
rank_tr = rank_tr[sample(nrow(rank_tr)),]
# Create 10 folds with equal size
folds = cut(seq(1,nrow(rank_tr)),breaks=10,labels=FALSE)
# Create the list for each fold
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
# Cross-validation settings
cv <- trainControl(method = "cv",
index  = my.indices)
require(caret)
require(kknn)
getModelInfo()$kknn$parameters
# Hyperparameter Tuning Grid
grid <- expand.grid(kmax    = 3:25,
distance = c(1,2,3),
kernel   = c('epanechnikov','rectangular'))
# grid
require(doParallel)
ncores <- 8
cl <- makePSOCKcluster(ncores)
registerDoParallel(cl)
# Train the model
textdummy$source <- as.vector(textdummy$source)
textdummy$rank <- as.vector(textdummy$rank)
textdummy$condition <- as.vector(textdummy$condition)
textdummy$funct <- as.vector(textdummy$funct)
textdummy$id <- as.vector(textdummy$id)
outcome <- c('rank')
ID <- c('id')
categorical <- c('condition', 'source', 'funct')
blueprint_textdummy <- recipe(x  = textdummy,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',3), 'outcome', 'ID'))
caret_knn <- caret::train(blueprint_textdummy,
data      = rank_tr,
method    = "kknn",
trControl = cv,
tuneGrid  = grid)
plot(caret_knn)
caret_knn$bestTune
# checking performance of knn algorithm on test dataset
predicted_te <- predict(caret_knn$finalModel, newdata = rank_te)
# r-square
cor(rank_te$rank, predicted_te)^2
# rmse
sqrt(mean((rank_te$rank - predicted_te)*2))
# mae
mean(abs(rank_te$rank -predicted_te))
omsi <- import(here("data", "omsidata.xlsx"))
View(omsi)
omsi <- import(here("data", "omsi.xlsx"))
# omsi <- import(here("data", "omsidata.xlsx"))
omsi <- import(here("data", "omsi.xlsx"))
omsi$condition <- as.factor(omsi$condition)
outcome <- c('squeaker_discovered')
ID <- c('participant')
categorical <- c('condition', 'gender', 'total_time', 'unique_actions', 'squeaker_time', 'target_functions', 'total_functions', 'age_months')
blueprint <- recipe(x  = omsi,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',8), 'outcome', 'ID')) %>%
step_zv(all_of(categorical))
View(omsi)
categorical <- c('condition', 'gender', 'total_time', 'unique_actions', 'squeak_time', 'target_functions', 'total_functions', 'age_months')
blueprint <- recipe(x  = omsi,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',8), 'outcome', 'ID')) %>%
step_zv(all_of(categorical))
set.seed(11102021)  # for reproducibility
om     <- sample(1:nrow(omsi), round(nrow(omsi) * 0.8))
omsi_tr  <- omsi[om, ]
omsi_te<- omsi[-om, ]
omsi_tr = omsi_tr[sample(nrow(omsi_tr)),]
folds = cut(seq(1,nrow(omsi_tr)),breaks=10,labels=FALSE)
# Creating the list for each fold
sen.indices <- vector('list',10)
for(i in 1:10){
sen.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method    = "cv",
index           = sen.indices,
classProbs      = TRUE,
summaryFunction = mnLogLoss)
caret_mod <- caret::train(omsi,
data      = omsi_tr,
method    = "glm",
family    = 'binomial',
metric    = 'logLoss',
trControl = cv)
caret_mod <- caret::train(blueprint,
data      = omsi_tr,
method    = "glm",
family    = 'binomial',
metric    = 'logLoss',
trControl = cv)
blueprint
levels(omsi_tr)
View(omsi)
View(omsi_te)
View(omsi_tr)
# omsi blueprint
blueprint <- recipe(x  = omsi,
vars  = c(categorical, outcome, ID),
roles = c(rep('predictor',8), 'outcome', 'ID'))
caret_mod <- caret::train(blueprint,
data      = omsi_tr,
method    = "glm",
family    = 'binomial'(link = 'logit'),
metric    = 'ROC',
trControl = cv)
require(glmnet)
caret_mod <- caret::train(blueprint,
data      = omsi_tr,
method    = "glmnet",
trControl = cv,
tuneGrid = grid)
# Train the model
grid <- data.frame (alpha = 0, lambda= seq(0.01, 3, .01))
caret_mod <- caret::train(blueprint,
data      = omsi_tr,
method    = "glmnet",
trControl = cv,
tuneGrid = grid)
View(blueprint)
# omsi blueprint
blueprint <- recipe(x  = omsi,
vars  = colnames(omsi),
roles = c(rep('predictor',8), 'outcome', 'ID')) %>%
step_zv(all_numeric()) %>%
step_nzv(all_numeric()) %>%
step_impute_mean(all_numeric()) %>%
step_normalize(all_numeric_predictors()) %>%
step_corr(all_numeric(),threshold=0.9)
outcome <- c('squeaker_discovered')
ID <- c('participant')
categorical <- c('condition', 'gender', 'total_time', 'unique_actions', 'squeak_time', 'target_functions', 'total_functions', 'age_months')
blueprint <- recipe(x  = omsi,
vars  = colnames(omsi),
roles = c(rep('predictor',8), 'outcome')) %>%
step_zv(all_numeric()) %>%
step_nzv(all_numeric()) %>%
step_impute_mean(all_numeric()) %>%
step_normalize(all_numeric_predictors()) %>%
step_corr(all_numeric(),threshold=0.9)
blueprint <- recipe(x  = omsi,
vars  = colnames(omsi),
roles = c(rep('predictor',8), 'outcome'))
blueprint <- recipe(x  = omsi,
vars  = colnames(omsi),
roles = c(rep('predictor',8), 'outcome', 'ID')) %>%
step_zv(all_numeric()) %>%
step_nzv(all_numeric()) %>%
step_impute_mean(all_numeric()) %>%
step_normalize(all_numeric_predictors()) %>%
step_corr(all_numeric(),threshold=0.9)
# omsi <- import(here("data", "omsidata.xlsx"))
omsi <- import(here("data", "omsi.xlsx"))
outcome <- c('squeaker_discovered')
ID <- c('participant')
categorical <- c('condition', 'gender', 'total_time', 'unique_actions', 'squeak_time', 'target_functions', 'total_functions', 'age_months')
blueprint <- recipe(x  = omsi,
vars  = colnames(omsi),
roles = c(rep('predictor',8), 'outcome', 'ID')) %>%
step_zv(all_numeric()) %>%
step_nzv(all_numeric()) %>%
step_impute_mean(all_numeric()) %>%
step_normalize(all_numeric_predictors()) %>%
step_corr(all_numeric(),threshold=0.9)
set.seed(11102021)  # for reproducibility
om     <- sample(1:nrow(omsi), round(nrow(omsi) * 0.8))
omsi_tr  <- omsi[om, ]
omsi_te<- omsi[-om, ]
# 10-fold cross-validation without regularization
omsi_tr = omsi_tr[sample(nrow(omsi_tr)),]
# Creating 10 folds with equal size
folds = cut(seq(1,nrow(omsi_tr)),breaks=10,labels=FALSE)
sen.indices <- vector('list',10)
for(i in 1:10){
sen.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method    = "cv",
index           = sen.indices)
# Train the model
grid <- data.frame (alpha = 0, lambda= seq(0.01, 3, .01))
caret_mod <- caret::train(blueprint,
data      = omsi_tr,
method    = "glmnet",
trControl = cv,
tuneGrid = grid)
ridge <- caret::train(blueprint,
data      = omsi_tr,
method    = "glmnet",
trControl = cv,
tuneGrid = grid)
ridge$results
# ridge$results
ridge$bestTune
plot(ridge)
predicted_te_ridge <- predict(ridge, omsi_te)
rsq_te <- cor(prediced_te_ridge, omsi_te$squeaker_discovered)^2  $predicted_te,predicted_eval$sen_test_numeric)^2
rsq_te <- cor(prediced_te_ridge, omsi_te$squeaker_discovered)^2
rsq_te <- cor(predicted_te_ridge, omsi_te$squeaker_discovered)^2
rsq_te
mae_te <- mean(abs(omsi_te$squeaker_discovered - predicted_te_ridge))
mae_te
rmse_te <- sqrt(mean((omsi_te$squeaker_discovered -predicted_te_ridge)^2))
rmse_te
require(vip)
vip(ridge, num_features = 10, geom = "point") +
theme_bw()
coefs <- coef(ridge$finalModel,ridge$bestTune$lambda)
ind   <- order(abs(coefs),decreasing=T)
head(as.matrix(coefs[ind[-1],]),10)
