---
title             : "Final Project Report"
shorttitle        : "EDLD 654"
author: 
  - name          : "Diana DeWald"
    affiliation   : "1"
    corresponding : yes    
    address       : "Straub, 336"
    email         : "ddewald@uoregon.edu"
affiliation:
  - id            : "1"
    institution   : "University of Oregon"
authornote: |
 Github project link: https://github.com/d-dewald/Final_EDLD654 
  
abstract: |
  Secondary engagement (SE) represents a dyadic process of shared attention to an external referent. For infants, participating in such interactions provides a powerful nexus for learning across multiple domains (Tomasello, 1999). The quantity and quality of infants’ early SE interactions predict many facets of their subsequent socio-cognitive development, but may also be related to contextual factors like nutrition, SES, and maternal well-being (e.g., Adamson, & Bakeman, 1984). We developed a new SE task designed to assess this facet of neuro-cogntive development, and in this final, developed a machine learning model to predict maternal SE task outcomes from thiamine status, SES, and maternal well-being.
  
keywords          : "secondary engagement, thiamine, machine learning"
wordcount         : "5189"

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            :   
  papaja::apa6_pdf
---

```{r setup, include = FALSE}
library(papaja)
library(tidyverse)
library(devtools)
library(tinytex)
library(readr)
library(magrittr)
library(recipes)
library(psych)
library(finalfit)
library(dplyr)
library(caret)
library(glmnet)
library(recipes)
library(cutpointr)
library(kableExtra)
library(pastecs)

set_data <- rio::import("C:\\Users\\ddewa\\OneDrive\\Documents\\Oregon\\edld 654\\final_EDLD654\\SET_data.xlsx")
```

# Research problem 

This research was conducted within the context of a large, randomized controlled trial in Cambodia investigating possible links between maternal thiamine supplementation and breastfed infants’ neurocognitive development (Measelle, et al., 2021; Whitfield, 2019). The specific research question motivating these models asks whether thiamine supplementation group, SES, and maternal well-being impact maternal behavior on a novel Secondary Engagement (SE) task. These findings will allow researchers to understand the extent to which contextual factors like maternal nutrition, SES, and maternal well-being impact breastfed infant's neurocognitive development in an at risk sample. Major findings have been distributed to Cambodian government officials in the past, and have the potential to impact thiamine fortification practices in the country. As more findings emerge, they will be distributed to the affected population via publications in local journals accessible to Khmer-speaking individuals.


# Description of the data 

The data in this analysis were used with permission from Kyly Whitfield. During a 'baseline' assessment 2 weeks postnatal, mothers were given a nutritional supplement of thiamine hydrochloride in salt tablets in four randomly assigned dose groups: (the variable `unblinded_treatment` in our model): 0mg/d (placebo), 1.2mg/d (Estimated Average Requirement (EAR)), 2.4mg/d (doube EAR), and 10mg/d (positive control). Mothers were also given a questionnaire at the 2-week postnatal period, and at two later timepoints (12 weeks postnatal, 24 weeks postnatal), from which our SES and maternal well-being predictor variables are constructed. Mothers and infants also took part in the SE task at 12 weeks and 24 weeks postnatal (our outcome variable, which has been collapsed across age groups for this project), and video recordings were taken by local Khmer-speaking researchers. This task shows mother-infant dyads engaged in a face-to-face, tactile and auditory interaction composed of five 30-second time increments (called epochs). These videos were coded by a team of researchers at the University of Oregon measuring mothers' joint attention behaviors on 4 dimensions. For the purposes of this project, we are only assessing 2 behavioral dimensions, and limiting our analysis to one of five epochs.

There were three groups of predictor variables in the data. The first group reflected mother's thiamine supplementation treatment status (dose groups described above), and this variable was dummy coded using one-hot encoding method (1 column to begin with, 4 new columns following dummy coding). 

```{r thiamine, include = FALSE, warning = FALSE}

# thiamine supplementation group dummy coding

set_data$placebo <- ifelse(set_data$unblinded_treatment == '0', 1, 0)
set_data$EAR <- ifelse(set_data$unblinded_treatment == '1.2', 1, 0)
set_data$double_EAR <- ifelse(set_data$unblinded_treatment == '2.4', 1, 0)
set_data$positive_control <- ifelse(set_data$unblinded_treatment =='10', 1, 0)

```

The second group of predictors was a 'maternal well-being' variable made up of a total of 12 self-report items (4 from each timepoint). The 2-items in the postpartum depression screening were on a 4-point Likert scale ranging from 0-3 (i.e. PHQ-9) (Gjerdingen et al., 2009). These variables were dummy coded using one-hot encoding for all three timepoints (6 columns to begin with, and 27 new columns following dummy coding). In addition, two self-report questions were administered to mothers at all three timepoints reflecting maternal and infant sleep quality on a Likert scale from 1-5 (6 columns to begin with, and 27 new columns following dummy coding).

```{r wellbeing, include = FALSE, warning = FALSE}

# mother's baseline sleep dummy coding

set_data$base_m_sleep_notrested <- ifelse(set_data$baseline_mother_sleep == '1', 1, 0)
set_data$base_m_sleep_slightlyrested <- ifelse(set_data$baseline_mother_sleep == '2', 1, 0)
set_data$base_m_sleep_somewhatrested <- ifelse(set_data$baseline_mother_sleep == '3', 1, 0)
set_data$base_m_sleep_mostlyrested <- ifelse(set_data$baseline_mother_sleep == '4', 1, 0)
set_data$base_m_sleep_definitelyrested <- ifelse(set_data$baseline_mother_sleep == '5', 1, 0)


# infant's baseline sleep dummy coding

set_data$base_i_sleep_notrested <- ifelse(set_data$baseline_infant_sleep == '1', 1, 0)
set_data$base_i_sleep_slightlyrested <- ifelse(set_data$baseline_infant_sleep == '2', 1, 0)
set_data$base_i_sleep_somewhatrested <- ifelse(set_data$baseline_infant_sleep == '3', 1, 0)
set_data$base_i_sleep_mostlyrested <- ifelse(set_data$baseline_infant_sleep == '4', 1, 0)
set_data$base_i_sleep_definitelyrested <- ifelse(set_data$baseline_infant_sleep == '5', 1, 0)




# mother's midline sleep dummy coding

set_data$mid_m_sleep_notrested <- ifelse(set_data$midline_mother_sleep == '1', 1, 0)
set_data$mid_m_sleep_slightlyrested <- ifelse(set_data$midline_mother_sleep == '2', 1, 0)
set_data$mid_m_sleep_somewhatrested <- ifelse(set_data$midline_mother_sleep == '3', 1, 0)
set_data$mid_m_sleep_mostlyrested <- ifelse(set_data$midline_mother_sleep == '4', 1, 0)
set_data$mid_m_sleep_definitelyrested <- ifelse(set_data$midline_mother_sleep == '5', 1, 0)

# infant's midline sleep dummy coding

set_data$mid_i_sleep_notrested <- ifelse(set_data$midline_infant_sleep == '1', 1, 0)
set_data$mid_i_sleep_slightlyrested <- ifelse(set_data$midline_infant_sleep == '2', 1, 0)
set_data$mid_i_sleep_somewhatrested <- ifelse(set_data$midline_infant_sleep == '3', 1, 0)
set_data$mid_i_sleep_mostlyrested <- ifelse(set_data$midline_infant_sleep == '4', 1, 0)
set_data$mid_i_sleep_definitelyrested <- ifelse(set_data$midline_infant_sleep == '5', 1, 0)




# mother's endline sleep dummy coding

set_data$end_m_sleep_notrested <- ifelse(set_data$endline_mother_sleep == '1', 1, 0)
set_data$end_m_sleep_slightlyrested <- ifelse(set_data$endline_mother_sleep == '2', 1, 0)
set_data$end_m_sleep_somewhatrested <- ifelse(set_data$endline_mother_sleep == '3', 1, 0)
set_data$end_m_sleep_mostlyrested <- ifelse(set_data$endline_mother_sleep == '4', 1, 0)
set_data$end_m_sleep_definitelyrested <- ifelse(set_data$endline_mother_sleep == '5', 1, 0)

# infant's endline sleep dummy coding

set_data$end_i_sleep_notrested <- ifelse(set_data$endline_infant_sleep == '1', 1, 0)
set_data$end_i_sleep_slightlyrested <- ifelse(set_data$endline_infant_sleep == '2', 1, 0)
set_data$end_i_sleep_somewhatrested <- ifelse(set_data$endline_infant_sleep == '3', 1, 0)
set_data$end_i_sleep_mostlyrested <- ifelse(set_data$endline_infant_sleep == '4', 1, 0)
set_data$end_i_sleep_definitelyrested <- ifelse(set_data$endline_infant_sleep == '5', 1, 0)




# mother's baseline self report of feeling down (low mood)

set_data$base_down_0 <- ifelse(set_data$baseline_down == '0', 1, 0)
set_data$base_down_1 <- ifelse(set_data$baseline_down == '1', 1, 0)
set_data$base_down_2<- ifelse(set_data$baseline_down == '2', 1, 0)
set_data$base_down_3 <- ifelse(set_data$baseline_down == '3', 1, 0)


# mother's basline self report of anhedonia (no interest in activities)

set_data$base_anhedonia_0 <- ifelse(set_data$baseline_anhedonia == '0', 1, 0)
set_data$base_anhedonia_1 <- ifelse(set_data$baseline_anhedonia == '1', 1, 0)
set_data$base_anhedonia_2 <- ifelse(set_data$baseline_anhedonia == '2', 1, 0)
set_data$base_anhedonia_3 <- ifelse(set_data$baseline_anhedonia == '3', 1, 0)



# mother's midline self report of feeling down (low mood)

set_data$mid_down_0 <- ifelse(set_data$midline_down == '0', 1, 0)
set_data$mid_down_1 <- ifelse(set_data$midline_down == '1', 1, 0)
set_data$mid_down_2<- ifelse(set_data$midline_down == '2', 1, 0)
set_data$mid_down_3 <- ifelse(set_data$midline_down == '3', 1, 0)


# mother's midline self report of anhedonia (no interest in activities)

set_data$mid_anhedonia_0 <- ifelse(set_data$midline_anhedonia == '0', 1, 0)
set_data$mid_anhedonia_1 <- ifelse(set_data$midline_anhedonia == '1', 1, 0)
set_data$mid_anhedonia_2 <- ifelse(set_data$midline_anhedonia == '2', 1, 0)
set_data$mid_anhedonia_3 <- ifelse(set_data$midline_anhedonia == '3', 1, 0)


# mother's endline self report of feeling down (low mood)

set_data$end_down_0 <- ifelse(set_data$endline_down == '0', 1, 0)
set_data$end_down_1 <- ifelse(set_data$endline_down == '1', 1, 0)
set_data$end_down_2<- ifelse(set_data$endline_down == '2', 1, 0)
set_data$end_down_3 <- ifelse(set_data$endline_down == '3', 1, 0)


# mother's endline self report of anhedonia (no interest in activities)

set_data$end_anhedonia_0 <- ifelse(set_data$endline_anhedonia == '0', 1, 0)
set_data$end_anhedonia_1 <- ifelse(set_data$endline_anhedonia == '1', 1, 0)
set_data$end_anhedonia_2 <- ifelse(set_data$endline_anhedonia == '2', 1, 0)
set_data$end_anhedonia_3 <- ifelse(set_data$endline_anhedonia == '3', 1, 0)


```

The third group of predictors had to do with SES, and was comprised of 18 columns in the original data, ranging from items about wealth quintile of the families, to questions about occupation, education, whether family had a bank account, house materials, toilet facilities, and whether appliances were present in the home. Nine of these items were already coded into binary form (yes or no question), so dummy coding created two new columns per variable (9 columns to begin with, and 18 new columns following dummy coding). The remainder of these variables (`wealth_quintile`, `mother_education_level`, `partner_education_level`, `mother_occupation`, `floow_material`, `exterior_walls_material`, `fuel_type`, `water_source`, `toilet_type`) were dummy coded using the one-hot encoding method (18 columns to being with, and 55 new columns following dummy coding).

```{r ses, include = FALSE, warning = FALSE}

# wealth quintile dummy coding

set_data$wealth_quintile_1 <- ifelse(set_data$wealth_quintile == '1', 1, 0)
set_data$wealth_quintile_2 <- ifelse(set_data$wealth_quintile == '2', 1, 0)
set_data$wealth_quintile_3<- ifelse(set_data$wealth_quintile == '3', 1, 0)
set_data$wealth_quintile_4 <- ifelse(set_data$baseline_mother_sleep == '4', 1, 0)


# mother's education level dummy coding

set_data$mother_education_0 <- ifelse(set_data$mother_education_level== '0', 1, 0)
set_data$mother_education_1 <- ifelse(set_data$mother_education_level == '1', 1, 0)
set_data$mother_education_2 <- ifelse(set_data$mother_education_level == '2', 1, 0)
set_data$mother_education_3 <- ifelse(set_data$mother_education_level == '3', 1, 0)
set_data$mother_education_4 <- ifelse(set_data$mother_education_level == '4', 1, 0)




# father's education level dummy coding


set_data$father_education_0 <- ifelse(set_data$partner_education_level== '0', 1, 0)
set_data$father_education_1 <- ifelse(set_data$partner_education_level == '1', 1, 0)
set_data$father_education_2 <- ifelse(set_data$partner_education_level == '2', 1, 0)
set_data$father_education_3 <- ifelse(set_data$partner_education_level == '3', 1, 0)
set_data$father_education_4 <- ifelse(set_data$partner_education_level == '4', 1, 0)


# mother's occupation dummy coding

set_data$mother_occupation_1 <- ifelse(set_data$mother_occupation == '1', 1, 0)
set_data$mother_occupation_2 <- ifelse(set_data$mother_occupation == '2', 1, 0)
set_data$mother_occupation_3 <- ifelse(set_data$mother_occupation == '3', 1, 0)
set_data$mother_occupation_4 <- ifelse(set_data$mother_occupation == '4', 1, 0)
set_data$mother_occupation_5 <- ifelse(set_data$mother_occupation == '5', 1, 0)
set_data$mother_occupation_6 <- ifelse(set_data$mother_occupation == '6', 1, 0)
set_data$mother_occupation_7 <- ifelse(set_data$mother_occupation == '7', 1, 0)



# In home electricity (yes/no)

set_data$electricity_yes <- ifelse(set_data$electricity == '1', 1, 0)
set_data$electricity_no <- ifelse(set_data$electricity == '0', 1, 0)

# In home television (yes/no)

set_data$television_yes <- ifelse(set_data$television == '1', 1, 0)
set_data$television_no <- ifelse(set_data$television == '0', 1, 0)


# In home refrigerator (yes/no)

set_data$refrigerator_yes <- ifelse(set_data$refrigerator == '1', 1, 0)
set_data$refrigerator_no <- ifelse(set_data$refrigerator == '0', 1, 0)


# In home cd or dvd player (yes/no)

set_data$cd_dvd_yes <- ifelse(set_data$cd_dvd == '1', 1, 0)
set_data$cd_dvd_no <- ifelse(set_data$cd_dvd == '0', 1, 0)


# In home wardrobe (yes/no)

set_data$wardrobe_yes <- ifelse(set_data$wardrobe == '1', 1, 0)
set_data$wardrobe_no <- ifelse(set_data$wardrobe == '0', 1, 0)

# In home source of power (yes/no)

set_data$power_yes <- ifelse(set_data$source_of_power == '1', 1, 0)
set_data$power_no <- ifelse(set_data$source_of_power == '0', 1, 0)


# does family own a motorcycle or scooter (yes/no)

set_data$scooter_yes <- ifelse(set_data$motorcycle_scooter == '1', 1, 0)
set_data$scooter_no <- ifelse(set_data$motorcycle_scooter == '0', 1, 0)


# does someone in the family own a watch (yes/no)

set_data$watch_yes <- ifelse(set_data$watch == '1', 1, 0)
set_data$watch_no <- ifelse(set_data$watch == '0', 1, 0)


# does someone in the family have a bank account (yes/no)

set_data$bank_account_yes <- ifelse(set_data$bank_account == '1', 1, 0)
set_data$bank_account_no <- ifelse(set_data$bank_account == '0', 1, 0)


# what is the material of the floors in the home 

set_data$floor_none <- ifelse(set_data$floor_material == '0', 1, 0)
set_data$floor_earth <- ifelse(set_data$floor_material == '1', 1, 0)
set_data$floor_bamboo <- ifelse(set_data$floor_material == '2', 1, 0)
set_data$floor_wood <- ifelse(set_data$floor_material == '3', 1, 0)
set_data$floor_parquet <- ifelse(set_data$floor_material == '4', 1, 0)
set_data$floor_tile <- ifelse(set_data$floor_material == '5', 1, 0)
set_data$floor_cement <- ifelse(set_data$floor_material == '6', 1, 0)


# what is the material of the walls in the home

set_data$wall_bamboo <- ifelse(set_data$exterior_walls_material == '1', 1, 0)
set_data$wall_palm <- ifelse(set_data$exterior_walls_material == '2', 1, 0)
set_data$wall_plywood <- ifelse(set_data$exterior_walls_material == '3', 1, 0)
set_data$wall_metal <- ifelse(set_data$exterior_walls_material == '4', 1, 0)
set_data$wall_cement <- ifelse(set_data$exterior_walls_material == '5', 1, 0)
set_data$wall_wood <- ifelse(set_data$exterior_walls_material == '6', 1, 0)
set_data$wall_bricks <- ifelse(set_data$exterior_walls_material == '7', 1, 0)
set_data$wall_cardboard <- ifelse(set_data$exterior_walls_material == '8', 1, 0)
set_data$wall_reused_wood <- ifelse(set_data$exterior_walls_material == '9', 1, 0)
set_data$wall_adobe <- ifelse(set_data$exterior_walls_material== '10', 1, 0)

# type of fuel used in the home

set_data$fuel_charcoal <- ifelse(set_data$fuel_type == '1', 1, 0)
set_data$fuel_wood <- ifelse(set_data$fuel_type == '2', 1, 0)
set_data$fuel_gas <- ifelse(set_data$fuel_type == '3', 1, 0)


# water source

set_data$water_piped<- ifelse(set_data$water_source == '1', 1, 0)
set_data$water_open_well <- ifelse(set_data$water_source == '2', 1, 0)
set_data$water_covered_well <- ifelse(set_data$water_source == '3', 1, 0)
set_data$water_borehole <- ifelse(set_data$water_source == '4', 1, 0)
set_data$water_surface <- ifelse(set_data$water_source == '5', 1, 0)
set_data$water_rain <- ifelse(set_data$water_source == '6', 1, 0)
set_data$water_bottled <- ifelse(set_data$water_source == '7', 1, 0)

# toilet type

set_data$toilet_none <- ifelse(set_data$toilet_type == '0', 1, 0)
set_data$toilet_sewer <- ifelse(set_data$toilet_type == '1', 1, 0)
set_data$toilet_septic <- ifelse(set_data$toilet_type == '2', 1, 0)
set_data$toilet_pour_sewer <- ifelse(set_data$toilet_type == '3', 1, 0)
set_data$toilet_pour_septic <- ifelse(set_data$toilet_type == '4', 1, 0)
set_data$toilet_latrine <- ifelse(set_data$toilet_type == '5', 1, 0)
set_data$toilet_vip <- ifelse(set_data$toilet_type == '6', 1, 0)

```


The data did not contain any missingness. The dataframe is now 136 rows and 167 columns.


## Basic descriptive stats
```{r descriptive, warning = FALSE}
head(describe(set_data))
# stat.desc(set_data)
```


# Description of the models

All variables are categorical, so I pre-processed them with an appropriate blueprint for two maternal behavioral codes 'joint engagement efforts' (JEE) and 'affective tone' (AT) (from SE task coding). In order to use logistic regression, I split the outcomes depending upon whether maternal behavior JEE reached a '3' (on 1-5 scale) and whether maternal behavior AT reached a '4' before loading the dataset to this document. I chose these cutoffs due to experience with coding (knowing that AT tends to demonstrat higher average codes and thus should have a higher cutoff value). In total, there were 129 categorical predictors based on a combination of the maternal well-being, SES, and thiamine status dummy codes

```{r preprocessing, include = FALSE, warning = FALSE}

# creating blueprint for JEE maternal behavior

outcome_jee <- c('JEE')

outcome_at <- c('AT')

ID <- c('sub_ID')


categorical <- c('placebo', 'EAR', 'double_EAR', 'positive_control', 'base_m_sleep_notrested', 'base_m_sleep_slightlyrested', 'base_m_sleep_somewhatrested', 'base_m_sleep_mostlyrested', 'base_m_sleep_definitelyrested', 'base_i_sleep_notrested', 'base_i_sleep_slightlyrested', 'base_i_sleep_somewhatrested', 'base_i_sleep_mostlyrested', 'base_i_sleep_definitelyrested', 'mid_m_sleep_notrested', 'mid_m_sleep_slightlyrested', 'mid_m_sleep_somewhatrested', 'mid_m_sleep_mostlyrested', 'mid_m_sleep_definitelyrested', 'mid_i_sleep_notrested', 'mid_i_sleep_slightlyrested', 'mid_i_sleep_somewhatrested', 'mid_i_sleep_mostlyrested', 'mid_i_sleep_definitelyrested',
'end_m_sleep_notrested', 'end_m_sleep_slightlyrested',
'end_m_sleep_somewhatrested', 'end_m_sleep_mostlyrested', 'end_m_sleep_definitelyrested', 'end_i_sleep_notrested',  'end_i_sleep_slightlyrested', 'end_i_sleep_somewhatrested', 
'end_i_sleep_mostlyrested', 'end_i_sleep_definitelyrested', 'base_down_0', 'base_down_1', 'base_down_2', 'base_down_3', 'base_anhedonia_0','base_anhedonia_1', 'base_anhedonia_2', 'base_anhedonia_3', 'mid_down_0', 'mid_down_1', 'mid_down_2','mid_down_3', 'mid_anhedonia_0', 'mid_anhedonia_1',  'mid_anhedonia_2', 'mid_anhedonia_3', 'end_down_0', 'end_down_1', 'end_down_2','end_down_3', 'end_anhedonia_0', 'end_anhedonia_1', 'end_anhedonia_2', 'end_anhedonia_3','wealth_quintile_1', 'wealth_quintile_2', 'wealth_quintile_3', 'wealth_quintile_4', 'mother_education_0','mother_education_1',  'mother_education_2', 'mother_education_3', 'mother_education_4', 'father_education_0', 'father_education_1', 'father_education_2','father_education_3','father_education_4','mother_occupation_1', 'mother_occupation_2', 'mother_occupation_3', 'mother_occupation_4', 'mother_occupation_5', 'mother_occupation_6', 'mother_occupation_7',
'electricity_yes','electricity_no', 'television_yes', 'television_no', 'refrigerator_yes', 'refrigerator_no', 'cd_dvd_yes', 'cd_dvd_no', 'wardrobe_yes', 'wardrobe_no', 'power_yes', 'power_no', 'scooter_yes','scooter_no', 'watch_yes', 'watch_no', 'bank_account_yes', 'bank_account_no', 'floor_none', 'floor_earth', 'floor_bamboo', 'floor_wood','floor_tile', 'floor_cement', 'wall_bamboo', 'wall_palm', 'wall_plywood', 'wall_metal', 'wall_cement', 'wall_wood', 'wall_cardboard', 'wall_reused_wood', 'wall_adobe', 'fuel_charcoal', 'fuel_wood', 'fuel_gas', 'water_piped', 'water_open_well', 'water_covered_well', 'water_borehole', 'water_surface', 'water_rain', 'water_bottled', 'toilet_none', 'toilet_sewer', 'toilet_septic', 'toilet_pour_sewer', 'toilet_pour_septic', 'toilet_latrine', 'toilet_vip') 


 blueprint_set_jee <- recipe(x  = set_data,
                    vars  = c(categorical, outcome_jee, ID),
                    roles = c(rep('predictor',129),'outcome','ID')) %>%
  step_indicate_na(all_of(categorical)) %>%
  step_zv(all_of(categorical)) %>%
    step_num2factor(JEE,
                  transform = function(x) x + 1,
                  levels=c('High','Low'))
 
 
blueprint_set_jee

 
prepare_set_jee <- prep(blueprint_set_jee, training = set_data)
 
prepare_set_jee

baked_set_jee <- bake(prepare_set_jee, new_data = set_data)



# preparing blueprint for AT

blueprint_set_at <- recipe(x  = set_data,
                    vars  = c(categorical, outcome_at, ID),
                    roles = c(rep('predictor',129),'outcome','ID')) %>%
  step_indicate_na(all_of(categorical)) %>%
  step_zv(all_of(categorical)) %>%
   step_num2factor(AT,
                  transform = function(x) x + 1,
                  levels=c('High','Low'))
 

blueprint_set_at

 
prepare_set_at <- prep(blueprint_set_jee, training = set_data)
 
prepare_set_at

baked_set_at <- bake(prepare_set_at, new_data = set_data)

```


```{r deleting, include = FALSE, warning = FALSE}
# getting rid of original treatment column 
set_data$unblinded_treatment <- NULL


# getting rid of maternal and infant sleep columns, and maternal self-report well-being columns
set_data$baseline_down <- NULL
set_data$baseline_anhedonia <- NULL
set_data$baseline_mother_sleep <- NULL
set_data$baseline_infant_sleep <- NULL
set_data$midline_down <- NULL
set_data$midline_anhedonia <- NULL
set_data$midline_mother_sleep <- NULL
set_data$midline_infant_sleep <- NULL
set_data$endline_down <- NULL
set_data$endline_anhedonia <- NULL
set_data$endline_mother_sleep <- NULL
set_data$endline_infant_sleep <- NULL


# getting rid of original SES columns
set_data$wealth_quintile <- NULL
set_data$mother_education_level <- NULL
set_data$partner_education_level <- NULL
set_data$mother_occupation <- NULL
set_data$electricity <- NULL
set_data$television <- NULL
set_data$refrigerator <- NULL
set_data$cd_dvd <- NULL
set_data$wardrobe <- NULL
set_data$source_of_power <- NULL
set_data$motorcycle_scooter <- NULL
set_data$watch <- NULL
set_data$bank_account <- NULL
set_data$floor_material <- NULL
set_data$exterior_walls_material <- NULL
set_data$fuel_type <- NULL
set_data$water_source <- NULL
set_data$toilet_type <- NULL


# getting rid of dummy columns that aren't adding any info (i.e., no observations of that type in this sample)
set_data$wall_bricks <- NULL
set_data$floor_parquet <- NULL

#decided to get rid of two maternal behavior codes since we have 4 and I don't want to create 12 models (I will create 6 with the other 2 behavior codes)

set_data$PO <- NULL
set_data$CR <- NULL

```

Following the deletion of 31 original extraneous variables, and getting rid of 2 dummy columns that didn't add any new information (i.e., there were no observations of that type in this sample), plus two maternal behavior columns I decided not to test, the prepared data set has 132 columns and 136 rows.


For both JEE and AT, I tested the performance of 3 models with nominal categorical outcomes: logistic regression with 10-fold cross validation and no penalty, logistic regression with ridge penalty, and logistic regression with lasso penalty. These models were selected because predictors are categorical, and the outcome is binary.

## Logistic regression with no penalty

```{r no penalty, include = FALSE, warning = FALSE}

# creating training and testing sets

set.seed(12102021)
  
set      <- sample(1:nrow(set_data), round(nrow(set_data) * 0.8))
set_train <- set_data[set, ]
set_test  <- set_data[-set, ]

set_tr = set_train[sample(nrow(set_train)),]

  # Creating 10 folds with equal size

folds = cut(seq(1,nrow(set_tr)),breaks=10,labels=FALSE)
  
  # Creating the list for each fold 
set.indices <- vector('list',10)
      for(i in 1:10){
        set.indices[[i]] <- which(folds!=i)
      }
    
# for tranControl, I used method "repeatedcv" 
 cv <- trainControl(method    = "cv",
                   index           = set.indices,
                   classProbs      = TRUE,
                   summaryFunction = mnLogLoss)

# Train the model for JEE

set.seed(123)
  
caret_set_jee <- caret::train(blueprint_set_jee, 
                          data      = set_tr, 
                          method    = "glm",
                          family    = 'binomial',
                          metric    = 'logLoss',
                          trControl = cv)

# Train the model for AT

caret_set_at <- caret::train(blueprint_set_at, 
                          data      = set_tr, 
                          method    = "glm",
                          family    = 'binomial',
                          metric    = 'logLoss',
                          trControl = cv)

caret_set_jee
caret_set_at
```

## Logistic regression with ridge penalty

```{r ridge, warning = FALSE, include = FALSE}
 caret::getModelInfo()$glmnet$parameters

grid_ridge <- data.frame(alpha = 0, lambda = seq(0.01,2,.01)) 

# model for JEE with ridge penalty
  
  ridge_jee <- caret::train(blueprint_set_jee, 
                        data      = set_data, 
                        method    = "glmnet",
                        family = 'binomial', 
                        metric = 'logLoss',
                        trControl = cv,
                        tuneGrid  = grid_ridge)
  
   ridge_at <- caret::train(blueprint_set_at, 
                        data      = set_data, 
                        method    = "glmnet",
                        family = 'binomial', 
                        metric = 'logLoss',
                        trControl = cv,
                        tuneGrid  = grid_ridge)
  
```

The optimal lambda value for a ridge penalty was 2.

## Logistic regression with lasso penalty

```{r 1.4, warning = FALSE, include = FALSE}


  # we set the value of alpha to 1 for lasso regression
  
grid_lasso <- data.frame(alpha = 1, lambda = seq(0.01,3,.01)) 
    
# Train the model for JEE

lasso_jee <- caret::train(blueprint_set_jee, 
                        data      = set_train, 
                        method    = "glmnet", 
                        trControl = cv,
                        tuneGrid  = grid_lasso)

# Train the model for AT

lasso_at <- caret::train(blueprint_set_at, 
                        data      = set_train, 
                        method    = "glmnet", 
                        trControl = cv,
                        tuneGrid  = grid_lasso)

lasso_jee$bestTune

lasso_at$bestTune
  
  
# comparing a model with different lambda values
grid_lasso.2 <- data.frame(alpha = 1, lambda = seq(0.001,2,.001)) 

    
# Train the models

lasso2_jee <- caret::train(blueprint_set_jee, 
                        data      = set_train, 
                        method    = "glmnet", 
                        trControl = cv,
                        tuneGrid  = grid_lasso.2)

lasso2_at <- caret::train(blueprint_set_at, 
                        data      = set_train, 
                        method    = "glmnet", 
                        trControl = cv,
                        tuneGrid  = grid_lasso.2)
  
#plot(lasso2_jee)
#plot(lasso2_at)

```


The models will be evaluated on the test dataset in the next section (Model Fit) based upon logLoss, AUC, ACC, True Positive Rate, True Negative Rate, and Precision.


# Model fit 

```{r modelfit JEE, warning = FALSE, include = FALSE}

# Using the JEE model without regularization

predicted_test_jee <- predict(caret_set_jee, set_test, type='prob')

dim(predicted_test_jee)

pred_class_jee <- ifelse(predicted_test_jee$High>.5,1,0)

confusion_jee <- table(set_test$JEE,pred_class_jee)

#found logLoss from results output

# Compute the AUC

cut.obj.jee <- cutpointr(x = predicted_test_jee$High,
                     class = set_test$JEE)

auc(cut.obj.jee)


# overall accuracy (ACC) = (TPR +TNR)/# samples

ACC <- sum(diag(confusion_jee))/136

ACC

# True Positive Rate

confusion_jee[2,2]/(confusion_jee[2,1]+confusion_jee[2,2])

# True Negative Rate

confusion_jee[1,1]/(confusion_jee[1,1]+confusion_jee[1,2])

# Precision

confusion_jee[2,2]/(confusion_jee[1,2]+confusion_jee[2,2])




# Jee model with ridge penalty
predicted_test_jee_2 <- predict(ridge_jee, set_test, type='prob')

dim(predicted_test_jee_2)

pred_class_jee_2 <- ifelse(predicted_test_jee$High>.5,1,0)

confusion_jee_2 <- table(set_test$JEE ,pred_class_jee_2)

# logloss
logLoss_ridge_jee <- c(0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392425, 0.7392373, 0.7392146, 0.7391869, 0.7391075, 0.7390284, 0.7389509, 0.7388659, 0.7387142, 0.7385588, 0.7384041, 0.7382513, 0.7380561, 0.7377867, 0.7375174, 0.7372490, 0.7369827, 0.7367129, 0.7364366, 0.7361638, 0.7358919, 0.7356217, 0.7353542, 0.7350990, 0.7348510, 0.7346038, 0.7343575, 0.7341130, 0.7338736, 0.7336463, 0.7334215, 0.7331974, 0.7329743, 0.7327527, 0.7325375, 0.7323320,
0.7321282, 0.7319250, 0.7317227, 0.7315217, 0.7313253, 0.7311384, 0.7309537, 0.7307695, 0.7305858, 0.7304034, 0.7302229, 0.7300505, 0.7298829, 0.7297159, 0.7295494, 0.7293836, 0.7292187, 0.7290569, 0.7289027, 0.7287513, 0.7286003, 0.7284497, 0.7282998, 0.7281507, 0.7280043, 0.7278644, 0.7277276, 0.7275910, 0.7274548, 0.7273191, 0.7271842, 0.7270504, 0.7269220, 0.7267977, 0.7266743, 0.7265511, 0.7264282, 0.7263060, 0.7261843, 0.7260645, 0.7259498, 0.7258381, 0.7257267, 0.7256156, 0.7255048, 0.7253945, 0.7252846, 0.7251763, 0.7250724, 0.7249714, 0.7248709, 0.7247707, 0.7246707, 0.7245710, 0.7244718, 0.7243733, 0.7242774, 0.7241855, 0.7240949, 0.7240045, 0.7239142, 0.7238242, 0.7237345, 0.7236452, 0.7235566, 0.7234707, 0.7233882, 0.7233066, 0.7232252, 0.7231439)
  

mean(logLoss_ridge_jee)

# Compute the AUC

cut.obj_jee_2 <- cutpointr(x     = predicted_test_jee_2$High,
                     class = set_test$JEE)

auc(cut.obj_jee_2)


# overall accuracy (ACC) 

ACC_jee.2 <- sum(diag(confusion_jee_2))/136

ACC_jee.2

# True Positive Rate

confusion_jee_2[2,2]/(confusion_jee_2[2,1]+confusion_jee_2[2,2])

# True Negative Rate

confusion_jee_2[1,1]/(confusion_jee_2[1,1]+confusion_jee_2[1,2])

# Precision

confusion_jee_2[2,2]/(confusion_jee_2[1,2]+confusion_jee_2[2,2])




# Jee model with lasso penalty
predicted_test_jee_3 <- predict(lasso_jee, set_test, type='prob')

dim(predicted_test_jee_3)

pred_class_jee_3 <- ifelse(predicted_test_jee_3$High>.5,1,0)

confusion_jee_3 <- table(set_test$JEE, pred_class_jee_3)

# logloss
logLoss_jee_3 <- c(1.2119458, 0.8182899, 0.7123946, 0.6779624, 0.6478124, 0.6261480, 0.6110151, 0.6056662, 0.6053776, 0.6083875, 0.6111872, 0.6123979, 0.6118006, 0.6111121, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143,
0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143,
0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143, 0.6107143)

mean(logLoss_jee_3)

# Compute the AUC

cut.obj_jee_3 <- cutpointr(x     = predicted_test_jee_3$High,
                     class = set_test$JEE)

auc(cut.obj_jee_3)


# overall accuracy (ACC) 

ACC_jee_3 <- sum(diag(confusion_jee_3))/136

ACC_jee_3

# True Positive Rate
dim(confusion_jee_3)
dim(confusion_jee_2)

confusion_jee_3[1,1]/(confusion_jee_3[2,1]+confusion_jee_3[1,1])

# True Negative Rate

confusion_jee_3[1,1]/(confusion_jee_3[1,1]+confusion_jee_3[2,1])

# Precision

confusion_jee_3[2,1]/(confusion_jee_3[1,1]+confusion_jee_3[2,1])

```


```{r modelfit AT, warning = FALSE, include = FALSE}

# Using the AT model without regularization

predicted_test_at <- predict(caret_set_at, set_test, type='prob')

dim(predicted_test_at)


pred_class_at <- ifelse(predicted_test_at$High>.5,1,0)

confusion_at <- table(set_test$AT,pred_class_at)

#found logLoss from results output

# Compute the AUC

cut.obj.at <- cutpointr(x = predicted_test_at$High,
                     class = set_test$AT)

auc(cut.obj.at)


# overall accuracy (ACC) = (TPR +TNR)/# samples

ACC_at <- sum(diag(confusion_at))/136

ACC_at

# True Positive Rate

confusion_at[2,2]/(confusion_at[2,1]+confusion_at[2,2])

# True Negative Rate

confusion_at[1,1]/(confusion_at[1,1]+confusion_at[1,2])

# Precision

confusion_at[2,2]/(confusion_at[1,2]+confusion_at[2,2])




# AT model with ridge penalty
predicted_test_at_2 <- predict(ridge_at, set_test, type='prob')

dim(predicted_test_at_2)

pred_class_at_2 <- ifelse(predicted_test_at_2$High>.5,1,0)

confusion_at_2 <- table(set_test$AT ,pred_class_at_2)

# logloss
logLoss_ridge_at <- c(0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465488, 0.8465321, 0.8464533, 0.8463746, 0.8462814, 0.8461159, 0.8459552, 0.8457960, 0.8456371, 0.8454822, 0.8453308, 0.8451472, 0.8449496, 0.8447524, 0.8445602, 0.8443709, 0.8441884, 0.8440067, 0.8438211, 0.8435996, 0.8433805, 0.8431497, 0.8428869, 0.8426023, 0.8423237, 0.8420481, 0.8417328, 0.8413913, 0.8410188, 0.8406487, 0.8402850, 0.8399244, 0.8395740, 0.8392291, 0.8388879, 0.8385503, 0.8382170, 0.8378875, 0.8375672, 0.8372514, 0.8369386, 0.8366290, 0.8363235, 0.8359889, 0.8356519, 0.8353191, 0.8349902, 0.8346625, 0.8343402, 0.8340196, 0.8337078, 0.8334017, 0.8330989, 0.8327977, 0.8324996, 0.8322046, 0.8319131, 0.8316291, 0.8313491, 0.8310724, 0.8307966, 0.8305240, 0.8302539, 0.8299868, 0.8297265, 0.8294700, 0.8292163, 0.8289638, 0.8287131, 0.8284658, 0.8282196, 0.8279795, 0.8277438, 0.8275102, 0.8272790, 0.8270482, 0.8268206, 0.8265946, 0.8263706, 0.8261523, 0.8259374, 0.8257243, 0.8255130, 0.8253020, 0.8250941, 0.8248875, 0.8246822, 0.8244825, 0.8242858, 0.8240905, 0.8238973, 0.8237044, 0.8235132, 0.8233243, 0.8231359, 0.8229513, 0.8227701, 0.8225911, 0.8224136, 0.8222374, 0.8220613, 0.8218875, 0.8217152, 0.8215434, 0.8213753, 0.8212101, 0.8210468, 0.8208848, 0.8207239)
  
mean(logLoss_ridge_at)

# Compute the AUC

cut.obj_at_2 <- cutpointr(x     = predicted_test_at_2$High,
                     class = set_test$AT)

auc(cut.obj_at_2)


# overall accuracy (ACC) 

ACC_at.2 <- sum(diag(confusion_at_2))/136

ACC_at.2

# True Positive Rate

confusion_at_2[2,2]/(confusion_at_2[2,1]+confusion_at_2[2,2])

# True Negative Rate

confusion_at_2[1,1]/(confusion_at_2[1,1]+confusion_at_2[1,2])

# Precision

confusion_at_2[2,2]/(confusion_at_2[1,2]+confusion_at_2[2,2])




# AT model with lasso penalty
predicted_test_at_3 <- predict(lasso_at, set_test, type='prob')

dim(predicted_test_at_3)

pred_class_at_3 <- ifelse(predicted_test_at_3$High>.5,1,0)

confusion_at_3 <- table(set_test$AT, pred_class_at_3)

lasso_at$results$logLoss

# logloss
logLoss_at_3 <- c(1.2339448, 0.8496843, 0.7274603, 0.6811227, 0.6599915, 0.6537151, 0.6540799, 0.6566577, 0.6630958, 0.6697493, 0.6746252, 0.6796085, 0.6854659, 0.6900430, 0.6905507, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345,
0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345, 0.6904345)

mean(logLoss_at_3)

# Compute the AUC

cut.obj_at_3 <- cutpointr(x     = predicted_test_at_3$High,
                     class = set_test$AT)

auc(cut.obj_at_3)


# overall accuracy (ACC) 

ACC_at_3 <- sum(diag(confusion_at_3))/136

ACC_at_3


# True Positive Rate

confusion_at_3[2,2]/(confusion_at_3[2,1]+confusion_at_3[2,2])

# True Negative Rate

confusion_at_3[1,1]/(confusion_at_3[1,1]+confusion_at_3[1,2])

# Precision

confusion_at_3[2,2]/(confusion_at_3[1,2]+confusion_at_3[2,2])


```

Provide the results of your model evaluation. Compare and contrasts results from different fits, including a discussion of model performance. Discuss your final model selection and the evidence that led you to this selection. If it is a classification problem, how did you choose a cut-off point for binary predictions? Did you consider different cut-off points?

# Data visualization 
Include at least two plots (or more) to help communicate your findings. The plots may be of initial data explorations, fits of individual models, and plots displaying the performance of competing models.

```{r datavis, warning = FALSE, echo = TRUE}

type <- c('Logistic Regression JEE', 'Logistic Regression with Ridge Penalty JEE', 'Logistic Regression with Lasso Penalty JEE', 'Logistic Regression AT', 'Logistic Regression with Ridge Penalty AT', 'Logistic Regression with Lasso Penalty AT')
LL <- c(13.74, 0.734, 0.614, 15.23, 0.839, 0.892)
AUC <- c(0.506, 0.8704, 0.5833, 0.5778, 0.6389, 0.6056)
ACC <- c(0.0882, 0.797, 0.0662, 0.0808, 0.0809, 0.1324)
TPR <- c(0.444, 0.444, 0.333, 0.5333, 0.0667, 0.6667)
TNR <- c(0.444, 0.444, 0.333, 0.25, 0.8333, 0.6667)
PRE <- c(0.6154, 0.6154, 0.667, 0.471, 0.333, 0.7143)


model_compare <- data.frame(type, LL, AUC, ACC, TPR, TNR, PRE)

kbl(model_compare)

plot(ridge_jee)
plot(ridge_at)
plot(lasso_jee)
plot(lasso_at)
```

For JEE, the best model appears to be logistic regression with ridge penalty. For AT, the best model is logistic regression with lasso penalty.

# Discussion/Conclusion 

```{r 1.6, warning = FALSE}

# Find and report the most important 10 predictors of JEE
coefs_jee <- coef(ridge_jee$finalModel,ridge_jee$bestTune$lambda)

coefs.zero_jee <- coefs_jee[which(coefs_jee[,1]==0),]
length(coefs.zero_jee)

coefs.nonzero_jee <- coefs_jee[which(coefs_jee[,1]!=0),]
length(coefs.nonzero_jee)

ind_jee   <- order(abs(coefs.nonzero_jee),decreasing=T)
head(as.matrix(coefs.nonzero_jee[ind_jee[-1]]),10)

# Find and report the most important 10 predictors of AT

coefs_at <- coef(lasso_at$finalModel,lasso_at$bestTune$lambda)

coefs.zero_at <- coefs_at[which(coefs_at[,1]==0),]
length(coefs.zero_at)

coefs.nonzero_at <- coefs_at[which(coefs_at[,1]!=0),]
length(coefs.nonzero_at)

ind_at  <- order(abs(coefs.nonzero_at),decreasing=T)
head(as.matrix(coefs.nonzero_at[ind_at[-1]]),10)

```

Discuss and summarize what you learned. Which variables were the most important in predicting your outcome?

For joint engagement efforts (JEE), the ten most important predictor variables were (negatively related) wall material (including reused wood and adobe), mother's occupation (particularly, whether mother was a garment worker), mother's depressed mood at endline report, toilet type, and having a refrigerator in the home. Positively related to the outcome was mother's being well-rested at endline, if families got their water from surface streams, if the family did not have a refrigerator, and if wall material was cardboard.

For Affective tone (AT), the ten most important positive predictor variables were mother's occupation (particularly, whether mother was a farmer), if mother was slightly rested at the endline questionnaire, whether the family had a wardrobe, and if the father had a high level of education. Negatively related to AT were whether the home had power, if mother's reported feeling down at midline questionnaire, if infants were sleeping somewhat well, if mother's were unemployed, and if father had no education.


Was this expected or surprising? 

Yes, some of these results were surprising, although the data doesn't accurately reflect exact maternal coding (I collapsed across ages and used some pre-existing data to substitute for new cases), so this may be why some of these predictors are showing up strongly in the model.

Were different models close in performance, or were there significant gaps in performance from different modeling approaches? 

There were pretty significant gaps in model performance, particularly for logLoss and ACC.


Are there practical/applied findings that could help the field of your interest based on your work? If yes, what are they?

I think I will need to do more analysis after we've coded the compete dataset in order to determine if these models will consistently give us results that are above chance levels.

\newpage

# References

Bakeman, R. & Adamson, L. B. (1988). Coordinating attention to people and objects in mother-infant and 
  peer-infant interaction. Child Development, 55(4), 1278-1289. 
  https://www.jstor.org/stable/1129997 

Gjerdingen, D., Crow, S., McGovern, P., Miner, M., & Center, B. (2009). Postpartum depression screening 
  at well-child visits: Validity of a 2-question screen and the PHQ-9. Annals of Family Medicine, 
  7(1), 63-70. https://doi.org/10.1370/afm.933 
  
Measelle, J. R., Baldwin, D. A., Gallant, J., Chan, K., Green, T. J., Wieringa, F. T., Borath, M., Prak, S., 
  Hampel, D., Shahab-Ferdows, S., Allen, L. H., Kroweun, H., & Whitfield, K. C. (2021). Thiamine 
  supplementation holds neurocognitive benefits for breastfed infants during the first year of life. 
  Annals of the New York Academy of Sciences, 0077-8923, 1-17. 
  https://doi.org/10.1111/nyas.14610 
  
Tomasello, M. (1999). The cultural origins of human cognition. Cambridge: Harvard University Press.

Whitfield, K., Kroweun, H., Green, T., Wieringa, F. T., Borath, M., Prak, S., Measelle, J. R., 
  Baldwin, D., Yellend, L. N., Leemaqz, S., Chan, K., & Gallant, J. (2019). Thiamine dose response in 
  human milk with supplementation among lactating women in Cambodia: Study protocol for a 
  double-blind, four-parallel arm randomized controlled trial. BMJ Open, 9, e029255. 
  https://doi:10.1136/bmjopen-2019-029255 

